{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7cf7466-511f-4946-8a30-8da966dd4454",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DAY 3 (11/01/26) – PySpark Transformations Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbda5912-e37f-4ab4-9ce2-505d157a19c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create  First PySpark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2899fc0a-33c7-4581-95c3-1394a181b66c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark Transformations Tutorial\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Check if Spark is working\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f70196f2-a5a9-4da7-a6c2-71290d92f996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1: Load E-commerce Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b5620b9-8fa7-4ee3-9cad-4e83b88d0518",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully!\n+-----------+-------+-----------------+--------+-----------------+\n|customer_id|   name|            email|    city|registration_date|\n+-----------+-------+-----------------+--------+-----------------+\n|          1|  Alice|  alice@email.com|New York|       2023-01-15|\n|          2|    Bob|    bob@email.com|  London|       2023-02-20|\n|          3|Charlie|charlie@email.com|   Paris|       2023-03-10|\n|          4|  David|  david@email.com|   Tokyo|       2023-04-05|\n|          5|    Eve|    eve@email.com|  Berlin|       2023-05-12|\n+-----------+-------+-----------------+--------+-----------------+\n\n+--------+-----------+----------+------+-----------+\n|order_id|customer_id|order_date|amount|   category|\n+--------+-----------+----------+------+-----------+\n|     101|          1|2024-01-01| 250.5|Electronics|\n|     102|          2|2024-01-02|150.75|   Clothing|\n|     103|          1|2024-01-03| 300.0|Electronics|\n|     104|          3|2024-01-04| 75.25|      Books|\n|     105|          1|2024-01-05| 120.0|   Clothing|\n|     106|          4|2024-01-06| 200.0|Electronics|\n|     107|          2|2024-01-07|  90.5|      Books|\n|     108|          3|2024-01-08| 180.0|Electronics|\n+--------+-----------+----------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive e-commerce dataset\n",
    "customers = spark.createDataFrame([\n",
    "    (1, 'Alice', 'alice@email.com', 'New York', '2023-01-15'),\n",
    "    (2, 'Bob', 'bob@email.com', 'London', '2023-02-20'),\n",
    "    (3, 'Charlie', 'charlie@email.com', 'Paris', '2023-03-10'),\n",
    "    (4, 'David', 'david@email.com', 'Tokyo', '2023-04-05'),\n",
    "    (5, 'Eve', 'eve@email.com', 'Berlin', '2023-05-12')\n",
    "], ['customer_id', 'name', 'email', 'city', 'registration_date'])\n",
    "\n",
    "orders = spark.createDataFrame([\n",
    "    (101, 1, '2024-01-01', 250.50, 'Electronics'),\n",
    "    (102, 2, '2024-01-02', 150.75, 'Clothing'),\n",
    "    (103, 1, '2024-01-03', 300.00, 'Electronics'),\n",
    "    (104, 3, '2024-01-04', 75.25, 'Books'),\n",
    "    (105, 1, '2024-01-05', 120.00, 'Clothing'),\n",
    "    (106, 4, '2024-01-06', 200.00, 'Electronics'),\n",
    "    (107, 2, '2024-01-07', 90.50, 'Books'),\n",
    "    (108, 3, '2024-01-08', 180.00, 'Electronics')\n",
    "], ['order_id', 'customer_id', 'order_date', 'amount', 'category'])\n",
    "\n",
    "print(\"✅ Data loaded successfully!\")\n",
    "customers.show()\n",
    "orders.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad8c0a49-8696-43ee-b812-dd502b858f1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2: Perform Complex Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f0a3116-0021-4ff2-87d1-5478e9617a19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers with orders (INNER JOIN):\n+-------+-----------------+--------+------+-----------+\n|   name|            email|order_id|amount|   category|\n+-------+-----------------+--------+------+-----------+\n|  Alice|  alice@email.com|     101| 250.5|Electronics|\n|    Bob|    bob@email.com|     102|150.75|   Clothing|\n|  Alice|  alice@email.com|     103| 300.0|Electronics|\n|Charlie|charlie@email.com|     104| 75.25|      Books|\n|  Alice|  alice@email.com|     105| 120.0|   Clothing|\n|  David|  david@email.com|     106| 200.0|Electronics|\n|    Bob|    bob@email.com|     107|  90.5|      Books|\n|Charlie|charlie@email.com|     108| 180.0|Electronics|\n+-------+-----------------+--------+------+-----------+\n\nAll customers (LEFT JOIN):\n+-----------+-------+-----------------+--------+-----------------+--------+----------+------+-----------+\n|customer_id|   name|            email|    city|registration_date|order_id|order_date|amount|   category|\n+-----------+-------+-----------------+--------+-----------------+--------+----------+------+-----------+\n|          1|  Alice|  alice@email.com|New York|       2023-01-15|     105|2024-01-05| 120.0|   Clothing|\n|          1|  Alice|  alice@email.com|New York|       2023-01-15|     103|2024-01-03| 300.0|Electronics|\n|          1|  Alice|  alice@email.com|New York|       2023-01-15|     101|2024-01-01| 250.5|Electronics|\n|          2|    Bob|    bob@email.com|  London|       2023-02-20|     107|2024-01-07|  90.5|      Books|\n|          2|    Bob|    bob@email.com|  London|       2023-02-20|     102|2024-01-02|150.75|   Clothing|\n|          3|Charlie|charlie@email.com|   Paris|       2023-03-10|     108|2024-01-08| 180.0|Electronics|\n|          3|Charlie|charlie@email.com|   Paris|       2023-03-10|     104|2024-01-04| 75.25|      Books|\n|          4|  David|  david@email.com|   Tokyo|       2023-04-05|     106|2024-01-06| 200.0|Electronics|\n|          5|    Eve|    eve@email.com|  Berlin|       2023-05-12|    NULL|      NULL|  NULL|       NULL|\n+-----------+-------+-----------------+--------+-----------------+--------+----------+------+-----------+\n\nTotal spending per customer:\n+-------+-----------+-----------+\n|   name|total_spent|order_count|\n+-------+-----------+-----------+\n|  Alice|      670.5|          3|\n|    Bob|     241.25|          2|\n|Charlie|     255.25|          2|\n|  David|      200.0|          1|\n|    Eve|        0.0|          0|\n+-------+-----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Which customers have placed orders?\n",
    "print(\"Customers with orders (INNER JOIN):\")\n",
    "result = customers.join(orders, on='customer_id', how='inner')\n",
    "result.select('name', 'email', 'order_id', 'amount', 'category').show()\n",
    "\n",
    "# Question 2: Show all customers, including those without orders\n",
    "print(\"All customers (LEFT JOIN):\")\n",
    "result = customers.join(orders, on='customer_id', how='left')\n",
    "result.show()\n",
    "\n",
    "# Question 3: Calculate total spent per customer\n",
    "print(\"Total spending per customer:\")\n",
    "result = orders.groupBy('customer_id') \\\n",
    "    .agg(F.sum('amount').alias('total_spent'),\n",
    "         F.count('order_id').alias('order_count'))\n",
    "\n",
    "# Join with customer names\n",
    "final = customers.join(result, on='customer_id', how='left') \\\n",
    "    .select('name', 'total_spent', 'order_count') \\\n",
    "    .fillna(0)  # Replace NULL with 0\n",
    "final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b17498a-bcf1-4b6c-9a2c-aa060413c8e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 3: Calculate Running Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3bae27c-e5dd-4dfa-8739-590d5becb2fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 9"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Running Totals:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+------+-----------+-------------+-----------------+\n|order_id|customer_id|order_date|amount|   category|running_total|cumulative_orders|\n+--------+-----------+----------+------+-----------+-------------+-----------------+\n|     101|          1|2024-01-01| 250.5|Electronics|        250.5|                1|\n|     102|          2|2024-01-02|150.75|   Clothing|       401.25|                2|\n|     103|          1|2024-01-03| 300.0|Electronics|       701.25|                3|\n|     104|          3|2024-01-04| 75.25|      Books|        776.5|                4|\n|     105|          1|2024-01-05| 120.0|   Clothing|        896.5|                5|\n|     106|          4|2024-01-06| 200.0|Electronics|       1096.5|                6|\n|     107|          2|2024-01-07|  90.5|      Books|       1187.0|                7|\n|     108|          3|2024-01-08| 180.0|Electronics|       1367.0|                8|\n+--------+-----------+----------+------+-----------+-------------+-----------------+\n\nRunning Totals by Category:\n+--------+-----------+----------+------+-----------+----------------------+\n|order_id|customer_id|order_date|amount|   category|category_running_total|\n+--------+-----------+----------+------+-----------+----------------------+\n|     104|          3|2024-01-04| 75.25|      Books|                 75.25|\n|     107|          2|2024-01-07|  90.5|      Books|                165.75|\n|     102|          2|2024-01-02|150.75|   Clothing|                150.75|\n|     105|          1|2024-01-05| 120.0|   Clothing|                270.75|\n|     101|          1|2024-01-01| 250.5|Electronics|                 250.5|\n|     103|          1|2024-01-03| 300.0|Electronics|                 550.5|\n|     106|          4|2024-01-06| 200.0|Electronics|                 750.5|\n|     108|          3|2024-01-08| 180.0|Electronics|                 930.5|\n+--------+-----------+----------+------+-----------+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'orders' DataFrame is defined\n",
    "try:\n",
    "    orders\n",
    "except NameError:\n",
    "    customers = spark.createDataFrame([\n",
    "        (1, 'Alice', 'alice@email.com', 'New York', '2023-01-15'),\n",
    "        (2, 'Bob', 'bob@email.com', 'London', '2023-02-20'),\n",
    "        (3, 'Charlie', 'charlie@email.com', 'Paris', '2023-03-10'),\n",
    "        (4, 'David', 'david@email.com', 'Tokyo', '2023-04-05'),\n",
    "        (5, 'Eve', 'eve@email.com', 'Berlin', '2023-05-12')\n",
    "    ], ['customer_id', 'name', 'email', 'city', 'registration_date'])\n",
    "    orders = spark.createDataFrame([\n",
    "        (101, 1, '2024-01-01', 250.50, 'Electronics'),\n",
    "        (102, 2, '2024-01-02', 150.75, 'Clothing'),\n",
    "        (103, 1, '2024-01-03', 300.00, 'Electronics'),\n",
    "        (104, 3, '2024-01-04', 75.25, 'Books'),\n",
    "        (105, 1, '2024-01-05', 120.00, 'Clothing'),\n",
    "        (106, 4, '2024-01-06', 200.00, 'Electronics'),\n",
    "        (107, 2, '2024-01-07', 90.50, 'Books'),\n",
    "        (108, 3, '2024-01-08', 180.00, 'Electronics')\n",
    "    ], ['order_id', 'customer_id', 'order_date', 'amount', 'category'])\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Running total of orders by date\n",
    "window_spec = Window.orderBy('order_date') \\\n",
    "                    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "result = orders.withColumn(\n",
    "    'running_total',\n",
    "    F.sum('amount').over(window_spec)\n",
    ").withColumn(\n",
    "    'cumulative_orders',\n",
    "    F.count('order_id').over(window_spec)\n",
    ")\n",
    "\n",
    "print(\"Daily Running Totals:\")\n",
    "result.orderBy('order_date').show()\n",
    "\n",
    "# Running total by category\n",
    "category_window = Window.partitionBy('category') \\\n",
    "                        .orderBy('order_date') \\\n",
    "                        .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "result = orders.withColumn(\n",
    "    'category_running_total',\n",
    "    F.sum('amount').over(category_window)\n",
    ")\n",
    "\n",
    "print(\"Running Totals by Category:\")\n",
    "result.orderBy('category', 'order_date').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "678ee359-a275-4aa6-a188-9574dacc0e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 4: Create Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5941718-9f99-402a-8773-8d1c7eeda418",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 11"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Features:\n+-----------+-------+-----------------+--------+-----------------+-----------------------+--------------+---------------+--------+\n|customer_id|   name|            email|    city|registration_date|days_since_registration|lifetime_value|avg_order_value| segment|\n+-----------+-------+-----------------+--------+-----------------+-----------------------+--------------+---------------+--------+\n|          1|  Alice|  alice@email.com|New York|       2023-01-15|                   1092|         670.5|          223.5|    Gold|\n|          2|    Bob|    bob@email.com|  London|       2023-02-20|                   1056|        241.25|        120.625|  Silver|\n|          3|Charlie|charlie@email.com|   Paris|       2023-03-10|                   1038|        255.25|        127.625|  Silver|\n|          4|  David|  david@email.com|   Tokyo|       2023-04-05|                   1012|         200.0|          200.0|  Silver|\n|          5|    Eve|    eve@email.com|  Berlin|       2023-05-12|                    975|          NULL|           NULL|Inactive|\n+-----------+-------+-----------------+--------+-----------------+-----------------------+--------------+---------------+--------+\n\nFinal Customer Profile:\n+-----------+-------+-----------------+--------+-----------------+-----------------------+--------------+---------------+--------+------------------+\n|customer_id|name   |email            |city    |registration_date|days_since_registration|lifetime_value|avg_order_value|segment |preferred_category|\n+-----------+-------+-----------------+--------+-----------------+-----------------------+--------------+---------------+--------+------------------+\n|1          |Alice  |alice@email.com  |New York|2023-01-15       |1092                   |670.5         |223.5          |Gold    |Electronics       |\n|2          |Bob    |bob@email.com    |London  |2023-02-20       |1056                   |241.25        |120.625        |Silver  |Clothing          |\n|3          |Charlie|charlie@email.com|Paris   |2023-03-10       |1038                   |255.25        |127.625        |Silver  |Electronics       |\n|4          |David  |david@email.com  |Tokyo   |2023-04-05       |1012                   |200.0         |200.0          |Silver  |Electronics       |\n|5          |Eve    |eve@email.com    |Berlin  |2023-05-12       |975                    |NULL          |NULL           |Inactive|NULL              |\n+-----------+-------+-----------------+--------+-----------------+-----------------------+--------------+---------------+--------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# 1. Customer lifetime value (total spent)\n",
    "clv = orders.groupBy('customer_id') \\\n",
    "    .agg(F.sum('amount').alias('lifetime_value'))\n",
    "\n",
    "# 2. Average order value\n",
    "aov = orders.groupBy('customer_id') \\\n",
    "    .agg(F.avg('amount').alias('avg_order_value'))\n",
    "\n",
    "# 3. Days since registration\n",
    "customers_enhanced = customers.withColumn(\n",
    "    'days_since_registration',\n",
    "    F.datediff(F.current_date(), F.col('registration_date'))\n",
    ")\n",
    "\n",
    "# 4. Customer segmentation (using UDF)\n",
    "@udf(returnType=StringType())\n",
    "def segment_customer(lifetime_value):\n",
    "    if lifetime_value is None:\n",
    "        return 'Inactive'\n",
    "    elif lifetime_value < 100:\n",
    "        return 'Bronze'\n",
    "    elif lifetime_value < 300:\n",
    "        return 'Silver'\n",
    "    else:\n",
    "        return 'Gold'\n",
    "\n",
    "# Combine all features\n",
    "final_customers = customers_enhanced \\\n",
    "    .join(clv, on='customer_id', how='left') \\\n",
    "    .join(aov, on='customer_id', how='left') \\\n",
    "    .withColumn('segment', segment_customer('lifetime_value'))\n",
    "\n",
    "print(\"Customer Features:\")\n",
    "final_customers.show()\n",
    "\n",
    "# 5. Category preference per customer\n",
    "category_pref = orders.groupBy('customer_id', 'category') \\\n",
    "    .agg(F.sum('amount').alias('category_total')) \\\n",
    "    .withColumn(\n",
    "        'rank',\n",
    "        F.rank().over(Window.partitionBy('customer_id').orderBy(F.desc('category_total')))\n",
    "    ).filter(F.col('rank') == 1) \\\n",
    "    .select('customer_id', F.col('category').alias('preferred_category'))\n",
    "\n",
    "final_customers = final_customers.join(category_pref, on='customer_id', how='left')\n",
    "\n",
    "print(\"Final Customer Profile:\")\n",
    "final_customers.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}